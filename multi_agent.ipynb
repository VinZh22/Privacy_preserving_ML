{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as rd\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs, make_moons, make_circles, make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import src.privacy_ml as ml #import split_horizontally, split_into_random_subsets, stepForward, stepForwardMono, stepForward_2\n",
    "import src.logistic_reg as lr #import cost\n",
    "import src.util as util\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_agents = 10\n",
    "seed = 42\n",
    "\n",
    "T = 1000\n",
    "mu = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = make_moons(n_samples=1000, noise=0.3)\n",
    "\n",
    "\n",
    "Y_formated = OneHotEncoder(categories='auto').fit_transform(Y.reshape(-1,1)).toarray()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=seed, test_size=0.4)\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(X[:,0], X[:,1], c=Y)\n",
    "plt.title(\"Data\")\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(X_train[:,0], X_train[:,1], c=Y_train)\n",
    "plt.title(\"Train\")\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(X_test[:,0], X_test[:,1], c=Y_test)\n",
    "plt.title(\"Test\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va trier les points par rapport à leur abscisse, pour simuler un effet de proximité entre les points, et utiliser cette proximité pour délimiter les différents agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_agent, Y_agent = ml.split_into_random_subsets(X_train, Y_train, random_state=seed)\n",
    "#X_agent, Y_agent = ml.split_horizontally(X_train, Y_train)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=int(num_agents/2), figsize=(20, 8))\n",
    "\n",
    "for i in range(num_agents):\n",
    "    row = i // (num_agents // 2)\n",
    "    col = i % (num_agents // 2)\n",
    "    colors = ['blue' if y== 0 else 'red' for y in Y_agent[i]]\n",
    "    axes[row, col].scatter(X_agent[i][:,0], X_agent[i][:,1], c=colors)\n",
    "    axes[row, col].set_title(f'Agent {i+1}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_agent_augmented = []\n",
    "for i in range(num_agents):\n",
    "    X_agent_augmented.append(np.concatenate([X_agent[i], X_agent[i]**2, X_agent[i]**3, X_agent[i]**4, X_agent[i]**5], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_augmented = np.concatenate([X_test, X_test**2, X_test**3, X_test**4, X_test**5], axis=1)\n",
    "X_train_augmented = np.concatenate([X_train, X_train**2, X_train**3, X_train**4, X_train**5], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = np.zeros((num_agents, num_agents))\n",
    "for i in range(num_agents):\n",
    "    for j in range(num_agents):\n",
    "        if j == i+1 or j == i-1:\n",
    "            G[i,j] = 1  \n",
    "    \n",
    "D = np.zeros(num_agents)\n",
    "c = np.zeros(num_agents)\n",
    "\n",
    "maxSize = np.max([x.shape[0] for x in X_agent])\n",
    "print(f\"Max: {maxSize}\")\n",
    "minSize = np.min([x.shape[0] for x in X_agent])\n",
    "print(f\"Min: {minSize}\")\n",
    "meanSize = np.mean([x.shape[0] for x in X_agent])\n",
    "print(f\"Mean: {meanSize}\")\n",
    "for i in range(num_agents):\n",
    "    D[i] = np.sum(G[i,:])\n",
    "    c[i] = X_agent[i].shape[0]/maxSize\n",
    "\n",
    "print(f\"G: {G}\")\n",
    "print(f\"D: {D}\")\n",
    "print(f\"c: {c}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression and Gradient Descent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In linear regression, we got a real-valued response\n",
    "\t\n",
    "$$\\hat{y} = \\theta_0 + \\theta_1 x_1 + \\cdots + \\theta_d x_d,$$\n",
    "    \n",
    "i.e., a linear combination of inputs, where $\\hat{y} \\in \\mathbf{R}$.\n",
    "\n",
    "In classification, we want an *indication* of how likely an instance is to belong to a particular class; a probability $\\in [0,1]$.  \n",
    "\n",
    "Given a real valued $z$, we can squish it to range $\\sigma(z) \\in [0,1]$ by feeding it through the **logistic function** aka **sigmoid function**:\n",
    "\t\t\n",
    "\\begin{equation}\n",
    "\\sigma(z) = \\frac{1}{1+\\exp(-z)}. \\hspace{1.5cm}(1)\n",
    "\\end{equation}\n",
    "\n",
    "Which looks like this: ![Sigmoid](https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/320px-Logistic-curve.svg.png)\n",
    "\n",
    "Therefore, we can treat this as a probability, i.e.,\n",
    "\n",
    "\\begin{align*}\n",
    "P(y=1|\\mathbf{x}) &= \\sigma(\\mathbf{\\theta}^\\top\\mathbf{x}), \\\\\n",
    "P(y=0|\\mathbf{x}) &= 1 - \\sigma(\\mathbf{\\theta}^\\top\\mathbf{x}), \n",
    "\\end{align*}\n",
    "\n",
    "where we omit the bias term and suppose that both $\\mathbf{\\theta}$ and $\\mathbf{x}$ are column vectors.\n",
    "\n",
    "In order to chose values for the parameters of logistic regression, we use **maximum likelihood estimation** (MLE). As such we are going to have two steps:\n",
    "\n",
    "1. write the likelihood function;\n",
    "2. find the values of $\\theta$ that maximize the log-likelihood function.\n",
    "\n",
    "\n",
    "We begin by defining the design matrix $X \\in \\mathbb{R}^{n,d}$ containing our data points $x_i^T \\in \\mathbb{R}^{1\\times d}$ on its rows and our column vector of model paramters $\\theta \\in \\mathbb{R}^{d\\times 1}.$\n",
    "The labels that we are predicting are binary, this means that we can interpret each label as a Bernoulli random variable: $Y \\sim Ber(p)$ where $p = \\sigma(\\mathbf{\\theta}^\\top\\mathbf{x})$.\n",
    "\n",
    "Therefore, we can write the probability of a data point as\n",
    "$$\n",
    "P\\left(Y=y|X=\\mathbf{x}\\right) = \\sigma(\\mathbf{\\theta}^\\top\\mathbf{x})^y \\cdot \\left[1-\\sigma(\\mathbf{\\theta}^\\top\\mathbf{x})\\right]^{(1-y)}.\n",
    "$$\n",
    "\n",
    "Given this probability mass function we can now write the **likelihood** of the whole dataset\n",
    "\n",
    "\\begin{equation}\n",
    "L(\\theta) = \\prod_{i=1}^n P(Y = y_i|\\mathbf{X} = \\mathbf{x}_i) = \\prod_{i=1}^n \\sigma(\\mathbf{\\theta}^\\top\\mathbf{x}_i)^{y_i} \\cdot \\left[1-\\sigma(\\mathbf{\\theta}^\\top\\mathbf{x}_i)\\right]^{(1-y_i)}. \\hspace{1.5cm}(2)\n",
    "\\end{equation}\n",
    "\n",
    "We can take the log of this function to transform the product into a sum and by doing that, we obtain the **log-likelihood**\n",
    "\n",
    "\\begin{equation}\n",
    "LL(\\theta) = \\sum_{i=1}^n \\left( y_i\\log{\\sigma(\\mathbf{\\theta}^\\top\\mathbf{x}_i)} + (1-y_i) \\log{\\left[1-\\sigma(\\mathbf{\\theta}^\\top\\mathbf{x}_i)\\right]} \\right). \\hspace{1.5cm}(3)\n",
    "\\end{equation}\n",
    "\n",
    "As you will remember from the first lab, our objective is to minimize the error by fitting our model to the data. However, the log-likelihood increases when the model is fitting better to the data. That's the reason why in logistic regression we take the *negative* log-likelihood (also known as **cost** function $E(\\theta)$).\n",
    "\n",
    "On a : $l(\\theta) = - \\sum_{i=1}^n \\left( y_i\\log{\\sigma(\\mathbf{\\theta}^\\top\\mathbf{x}_i)} + (1-y_i) \\log{\\left[1-\\sigma(\\mathbf{\\theta}^\\top\\mathbf{x}_i)\\right]} \\right).$\n",
    "donc la dérivée vaut : $\\nabla _\\theta l(\\theta) = -\\sum_{i=1}^n y_i (1-\\sigma(\\theta^Tx_i))x_i - (1-y_i) \\sigma(\\theta^Tx_i)x_i $\n",
    "\n",
    "$ \\nabla_\\theta l(\\theta) = -\\sum_{i=1}^n (y_i - \\sigma(\\theta^Tx_i)) x_i $\n",
    "\n",
    "Besoin du coeff de Lipschitz mais : https://proceedings.neurips.cc/paper_files/paper/2018/file/d54e99a6c03704e95e6965532dec148b-Paper.pdf\n",
    "\n",
    "Supposons que le sigmoid soit L-lip\n",
    "Alors \n",
    "\n",
    "$ \\nabla_\\theta l(\\theta_0) - \\nabla_\\theta l(\\theta_1)  = -\\sum_{i=1}^n (\\sigma(\\theta_1^Tx_i) - \\sigma(\\theta_0^Tx_i)) x_i$\n",
    "\n",
    "$| \\nabla_\\theta l(\\theta_0) - \\nabla_\\theta l(\\theta_1) |_2 \\leq \\sum_{i=1}^n L|(\\theta_1^T - \\theta_0^T)x_i| | x_i |_2  \\leq \\sum_{i=1}^n L|\\theta_1^T - \\theta_0|_2 |x_i|_2 | x_i |_2 $\n",
    "\n",
    "Or on a $L = \\frac{1}{4} $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "### Single Global Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "thetas_mono = np.random.rand(X_train_augmented.shape[1])\n",
    "costs_train_mono = np.zeros((T))\n",
    "costs_test_mono = np.zeros((T))\n",
    "\n",
    "train_acc = np.zeros((T))\n",
    "test_acc = np.zeros((T))\n",
    "\n",
    "for i in range(T):\n",
    "    thetas_mono = ml.stepForwardMono(thetas_mono, X_train_augmented, Y_train)\n",
    "    costs_train_mono[i] = lr.cost(thetas_mono, X_train_augmented, Y_train)\n",
    "    costs_test_mono[i] = lr.cost(thetas_mono, X_test_augmented, Y_test)\n",
    "\n",
    "    train_acc[i] = lr.accuracy(thetas_mono, X_train_augmented, Y_train)\n",
    "    test_acc[i] = lr.accuracy(thetas_mono, X_test_augmented, Y_test)\n",
    "\n",
    "    if i % (T/10) == 0:\n",
    "                print(f'Iteration {i} : Train: {costs_train_mono[i]:.4f} | Test: {costs_test_mono[i]:.4f}')\n",
    "\n",
    "# np.random.seed(seed)\n",
    "# thetas_agents_globalModel = [np.random.rand(X_agent_augmented[i].shape[1]) for i in range(num_agents)]\n",
    "\n",
    "# costs_train_agents_globalModel = np.zeros((T, num_agents))\n",
    "# costs_test_agents_globalModel = np.zeros((T, num_agents))\n",
    "\n",
    "# print(T)\n",
    "# for i in range(T):\n",
    "#     thetas_agents_globalModel = ml.stepForward(thetas_agents_globalModel, X_agent_augmented, Y_agent, num_agents, 0, c, G, D)\n",
    "#     for j in range(num_agents):\n",
    "#             costs_train_agents_globalModel[i,j] = lr.cost(thetas_agents_globalModel[j], X_agent_augmented[j], Y_agent[j])\n",
    "#             costs_test_agents_globalModel[i,j] = lr.cost(thetas_agents_globalModel[j], X_test_augmented, Y_test)\n",
    "#     if i % 1000 == 0 :\n",
    "#         print(f'Iteration {i+1} : Train: {np.mean(costs_train_agents_globalModel[i]):.4f} and {np.std(costs_train_agents_globalModel[i]):.4f} | Test: {np.mean(costs_test_agents_globalModel[i]):.4f} and {np.std(costs_test_agents_globalModel[i]):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(costs_train_mono, label=\"Mono Train\")\n",
    "plt.plot(costs_test_mono, label=\"Mono Test\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(train_acc, label=\"Train Acc\")\n",
    "plt.plot(test_acc, label=\"Test Acc\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# util.plot_curves(num_agents, costs_train_agents_globalModel, costs_test_agents_globalModel, \"Multiple Agents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple agents\n",
    "\n",
    "Agents dont share their models (perfectly private baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "thetas_agents_alone = [np.random.rand(X_agent_augmented[i].shape[1]) for i in range(num_agents)]\n",
    "\n",
    "costs_train_agents_alone = np.zeros((T, num_agents))\n",
    "costs_test_agents_alone = np.zeros((T, num_agents))\n",
    "costs_train_alone = np.zeros(T)\n",
    "costs_test_alone = np.zeros(T)\n",
    "acc_train_agents_alone = np.zeros((T, num_agents))\n",
    "acc_test_agents_alone = np.zeros((T, num_agents))\n",
    "\n",
    "print(\"Iter: Agents_Mean       | Total \")\n",
    "for i in range(T):\n",
    "    thetas_agents_alone = ml.stepForwardAlone(thetas_agents_alone, X_agent_augmented, Y_agent, num_agents)\n",
    "    for j in range(num_agents):\n",
    "            costs_train_agents_alone[i,j] = lr.cost(thetas_agents_alone[j], X_agent_augmented[j], Y_agent[j])\n",
    "            costs_test_agents_alone[i,j] = lr.cost(thetas_agents_alone[j], X_test_augmented, Y_test)\n",
    "\n",
    "            acc_train_agents_alone[i, j] = lr.accuracy(thetas_agents_alone[j], X_agent_augmented[j], Y_agent[j])\n",
    "            acc_test_agents_alone[i, j] = lr.accuracy(thetas_agents_alone[j], X_test_augmented, Y_test)\n",
    "\n",
    "    costs_train_alone[i] = lr.costDecentralized(thetas_agents_alone, X_agent_augmented, Y_agent, num_agents, G, D, c, mu)\n",
    "    costs_test_alone[i] = lr.costDecentralized(thetas_agents_alone, X_test_augmented, Y_test, num_agents, G, D, c, mu)\n",
    "\n",
    "    if i % (T/10) == 0 :\n",
    "        print(f'{i:3} : ({np.mean(costs_train_agents_alone[i]):.4f} , {np.mean(costs_test_agents_alone[i]):.4f}) | ({costs_train_alone[i]:.4f} , {costs_test_alone[i]:.4f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.plot_curves(num_agents, costs_train_agents_alone, costs_test_agents_alone, costs_train_alone, costs_test_alone, \"Multiple Agents - no collaboration\")\n",
    "util.plot_accuracy(num_agents, acc_train_agents_alone, acc_test_agents_alone, \"Acc - Multiple Agents - no collaboration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple agents\n",
    "\n",
    "All agents do a step after each other in a naive queue and share their models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "thetas_agents = [np.random.rand(X_agent_augmented[i].shape[1]) for i in range(num_agents)]\n",
    "\n",
    "costs_train_agents = np.zeros((T, num_agents))\n",
    "costs_test_agents = np.zeros((T, num_agents))\n",
    "costs_train = np.zeros(T)\n",
    "costs_test = np.zeros(T)\n",
    "acc_train_agents = np.zeros((T, num_agents))\n",
    "acc_test_agents = np.zeros((T, num_agents))\n",
    "\n",
    "print(\"Iter: Agents_Mean       | Total \")\n",
    "for i in range(T):\n",
    "    thetas_agents = ml.stepForward(thetas_agents, X_agent_augmented, Y_agent, num_agents, mu, c, G, D)\n",
    "    for j in range(num_agents):\n",
    "            costs_train_agents[i,j] = lr.cost(thetas_agents[j], X_agent_augmented[j], Y_agent[j])\n",
    "            costs_test_agents[i,j] = lr.cost(thetas_agents[j], X_test_augmented, Y_test)\n",
    "\n",
    "            acc_train_agents[i,j] = lr.accuracy(thetas_agents[j], X_agent_augmented[j], Y_agent[j])\n",
    "            acc_test_agents[i,j] = lr.accuracy(thetas_agents[j], X_test_augmented, Y_test)\n",
    "    costs_train[i] = lr.costDecentralized(thetas_agents, X_agent_augmented, Y_agent, num_agents, G, D, c, mu)\n",
    "    costs_test[i] = lr.costDecentralized(thetas_agents, X_test_augmented, Y_test, num_agents, G, D, c, mu)\n",
    "    if i % (T/10) == 0 :\n",
    "        print(f'{i:3} : ({np.mean(costs_train_agents[i]):.4f} , {np.mean(costs_test_agents[i]):.4f}) | ({costs_train[i]:.4f} , {costs_test[i]:.4f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.plot_curves(num_agents, costs_train_agents, costs_test_agents, costs_train, costs_test, \"Loss - Multiple Agents - simple queue\")\n",
    "util.plot_accuracy(num_agents, acc_train_agents, acc_test_agents, \"Acc - Multiple Agents - simple queue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.mean(acc_test_agents_alone, axis=1), label=\"No communication\")\n",
    "plt.plot(np.mean(acc_test_agents, axis=1), label=\"Open Communication\")\n",
    "plt.legend()\n",
    "plt.title(\"Acc - Alone / Collaboration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random drawing of Agents\n",
    "\n",
    "randint with global quota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "tracking  = np.zeros(num_agents) # pour mesurer le nombre de fois que chaque agent passe\n",
    "total_T = T*num_agents\n",
    "\n",
    "thetas_agents_rand = [np.random.rand(X_agent_augmented[i].shape[1]) for i in range(num_agents)]\n",
    "costs_test_agents_rand = np.zeros((total_T, num_agents))                 # ici on ne gardera en mémoire que les dernières valeurs\n",
    "costs_train_agents_rand = np.zeros((total_T, num_agents))\n",
    "costs_test_rand = np.zeros(total_T)\n",
    "costs_train_rand = np.zeros(total_T)\n",
    "\n",
    "acc_test_agents_rand = np.zeros((total_T, num_agents))               \n",
    "acc_train_agents_rand = np.zeros((total_T, num_agents))\n",
    "\n",
    "\n",
    "print(\"Iter: Agents_Mean       | Total \")\n",
    "for i in range (total_T) :\n",
    "    j = rd.randint(0, num_agents-1)\n",
    "    tracking[j] += 1\n",
    "\n",
    "    thetas_agents_rand = ml.stepForward_2(thetas_agents_rand, X_agent_augmented, Y_agent, j, num_agents, mu, c, G, D) \n",
    "\n",
    "    costs_train_agents_rand[i, j] = lr.cost(thetas_agents_rand[j], X_agent_augmented[j], Y_agent[j])\n",
    "    costs_test_agents_rand[i, j] = lr.cost(thetas_agents_rand[j], X_test_augmented, Y_test)\n",
    "\n",
    "    acc_train_agents_rand[i, j] = lr.accuracy(thetas_agents_rand[j], X_agent_augmented[j], Y_agent[j])\n",
    "    acc_test_agents_rand[i, j] = lr.accuracy(thetas_agents_rand[j], X_test_augmented, Y_test)\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        costs_train_rand[int(i/10)] = lr.costDecentralized(thetas_agents_rand, X_agent_augmented, Y_agent, num_agents, G, D, c, mu)\n",
    "        costs_test_rand[int(i/10)] = lr.costDecentralized(thetas_agents_rand, X_test_augmented, Y_test, num_agents, G, D, c, mu)\n",
    "        \n",
    "    if i % ((T/10)*num_agents) == 0 :\n",
    "        print(f'{int(i/num_agents):3} : ({np.mean(costs_train_agents_rand[i]):.4f} , {np.mean(costs_test_agents_rand[i]):.4f}) | ({costs_train_rand[int(i/10)]:.4f} , {costs_test_rand[int(i/10)]:.4f})')\n",
    "\n",
    "costs_train_agents_rand = util.reduce_cost_matrix(costs_train_agents_rand)\n",
    "costs_test_agents_rand = util.reduce_cost_matrix(costs_test_agents_rand)\n",
    "costs_train_rand = costs_train_rand[:T]\n",
    "costs_test_rand = costs_test_rand[:T]\n",
    "\n",
    "acc_train_agents_rand = util.reduce_cost_matrix(acc_train_agents_rand)\n",
    "acc_test_agents_rand = util.reduce_cost_matrix(acc_test_agents_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.plot_curves(num_agents, costs_train_agents_rand, costs_test_agents_rand, costs_train_rand, costs_test_rand, \"Loss - Multiple Agents - random draw\")\n",
    "util.plot_accuracy(num_agents, acc_train_agents_rand, acc_test_agents_rand, \"Acc - Multiple Agents - random draw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighting of Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "tracking  = np.zeros(num_agents)\n",
    "total_T = T*num_agents\n",
    "\n",
    "thetas_agents_weigh = [np.random.rand(X_agent_augmented[i].shape[1]) for i in range(num_agents)]\n",
    "costs_test_agents_weigh = np.zeros((total_T, num_agents))                 # ici on ne gardera en mémoire que les dernières valeurs\n",
    "costs_train_agents_weigh = np.zeros((total_T, num_agents))\n",
    "costs_test_weigh = np.zeros(total_T)\n",
    "costs_train_weigh = np.zeros(total_T)\n",
    "\n",
    "\n",
    "# on obtient les probabilités qu'on veut pour chaque modèle à chaque tirage\n",
    "coeffs_pond = np.zeros(num_agents)\n",
    "c_tot = 0\n",
    "for i in range (len(c)) :\n",
    "    c_tot += c[i]    \n",
    "for i in range (len(c)) :\n",
    "    coeffs_pond[i] = c[i]/c_tot\n",
    "    \n",
    "print(coeffs_pond)\n",
    "print(\"Iter: Agents_Mean       | Total \")\n",
    "\n",
    "for i in range(total_T) :\n",
    "    j = np.random.choice(10, 1, p=coeffs_pond)[0]\n",
    "    tracking[j] += 1\n",
    "\n",
    "    thetas_agents_weigh = ml.stepForward_2(thetas_agents_weigh, X_agent_augmented, Y_agent, j, num_agents, mu, c, G, D) \n",
    "\n",
    "    costs_train_agents_weigh[i, j] = (lr.cost(thetas_agents_weigh[j], X_agent_augmented[j], Y_agent[j]))\n",
    "    costs_test_agents_weigh[i, j] = (lr.cost(thetas_agents_weigh[j], X_test_augmented, Y_test))\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        costs_train_weigh[int(i/10)] = lr.costDecentralized(thetas_agents_weigh, X_agent_augmented, Y_agent, num_agents, G, D, c, mu)\n",
    "        costs_test_weigh[int(i/10)] = lr.costDecentralized(thetas_agents_weigh, X_test_augmented, Y_test, num_agents, G, D, c, mu)\n",
    "        \n",
    "        \n",
    "    if i % ((T/10)*num_agents) == 0 :\n",
    "        print(f'{int(i/num_agents):3} : ({np.mean(costs_train_agents_weigh[i]):.4f} , {np.mean(costs_test_agents_weigh[i]):.4f}) | ({costs_train_weigh[int(i/10)]:.4f} , {costs_test_weigh[int(i/10)]:.4f})')\n",
    "\n",
    "# costs_train_agents_weigh = util.reduce_cost_matrix(costs_train_agents_weigh)\n",
    "# costs_test_agents_weigh = util.reduce_cost_matrix(costs_test_agents_weigh)\n",
    "\n",
    "costs_train_agents_weigh_shifted = util.shift_non_zero_costs_to_front(costs_train_agents_weigh)\n",
    "costs_test_agents_weigh_shifted = util.shift_non_zero_costs_to_front(costs_test_agents_weigh)\n",
    "\n",
    "non_zero_counts = np.count_nonzero(costs_train_agents_weigh_shifted, axis=0)    \n",
    "max_non_zero = np.max(non_zero_counts)\n",
    "costs_train_weigh = costs_train_weigh[:max_non_zero]\n",
    "costs_test_weigh = costs_test_weigh[:max_non_zero]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.plot_curves_non_zero(num_agents, costs_train_agents_weigh_shifted, costs_test_agents_weigh_shifted, costs_train_weigh, costs_test_weigh, \"Multiple Agents - random weighted draw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Privacy\n",
    "\n",
    "On fait avec $\\delta = 0$ et $\\epsilon_i(t_i) = \\epsilon$\n",
    "\n",
    "Si on veut partir du $\\bar{\\epsilon}$, on va utiliser $\\delta$ et $\\bar{\\delta}$ tous nuls, et utiliser le théorème 1 (et la proposition 2 dans un deuxième temps) pour obtenir des epsilon.\n",
    "\n",
    "Ici on peut avoir des $\\bar{\\epsilon}$ très élevés\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.5 # -> ici on a donc epsilon_barre = epsilon * T = 500\n",
    "L_0 = 0.25\n",
    "\n",
    "print(type(epsilon))\n",
    "\n",
    "np.random.seed(seed)\n",
    "thetas_private = [np.random.rand(X_agent_augmented[i].shape[1]) for i in range(num_agents)]\n",
    "\n",
    "costs_train_private = np.zeros(T)\n",
    "costs_test_private = np.zeros(T)\n",
    "\n",
    "acc_train_private = np.zeros(T)\n",
    "acc_test_private = np.zeros(T)\n",
    "\n",
    "for i in range(T):\n",
    "    thetas_private = ml.stepForwardPrivate(thetas_private, X_agent_augmented, Y_agent, num_agents, mu, c, G, D, L_0, epsilon)\n",
    "    costs_train_private[i] = lr.costDecentralized(thetas_private, X_agent_augmented, Y_agent, num_agents, G, D, c, mu)\n",
    "    costs_test_private[i] = lr.costDecentralized(thetas_private, X_test_augmented, Y_test, num_agents, G, D, c, mu)\n",
    "\n",
    "    acc_train_private[i] = lr.accuracyAll(num_agents, thetas_private, X_agent_augmented, Y_agent)\n",
    "    acc_test_private[i] = lr.accuracyAll(num_agents, thetas_private, [X_test_augmented for i in range(num_agents)], [Y_test for i in range(num_agents)])\n",
    "    if i % (T/10) == 0 :\n",
    "        print(f'Iteration {i} : Train: {costs_train_private[i]:.4f} | Test: {costs_test_private[i]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(costs_train_private, label=\"Train\")\n",
    "plt.plot(costs_test_private, label=\"Test\")\n",
    "plt.title(\"Loss Private Model\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(acc_train_private, label=\"Train\")\n",
    "plt.plot(acc_test_private, label=\"Test\")\n",
    "plt.title(\"Acc Private Model\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(costs_test_private, label=\"Sharing Private\")\n",
    "#plt.plot(costs_test_alone, label=\"No Sharing\")\n",
    "plt.plot(costs_test_rand, label=\"Sharing Non Private\")\n",
    "plt.plot(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.mean(acc_test_agents_alone, axis=1), label=\"No Sharing\")\n",
    "plt.plot(np.mean(acc_test_agents_rand, axis=1), label=\"Open Sharing\")\n",
    "plt.plot(acc_test_private, label=\"Private Sharing\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random drawing using constant epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# epsilon = epsilon_barre / T # pour stepForwardPrivate normal\n",
    "\n",
    "# il faut réestimer le epsilon_barre lorsque le nombre d'étapes d'entraînement pour un modèle n'est pas exactement T \n",
    "\n",
    "#epsilon_barre = 500\n",
    "\n",
    "epsilon = 0.5\n",
    "L_0 = 0.25\n",
    "\n",
    "print(type(epsilon))\n",
    "\n",
    "np.random.seed(seed)\n",
    "tracking  = np.zeros(num_agents) # pour mesurer le nombre de fois que chaque agent passe\n",
    "total_T = T*num_agents\n",
    "\n",
    "thetas_agents_private_rand = [np.random.rand(X_agent_augmented[i].shape[1]) for i in range(num_agents)]\n",
    "costs_test_agents_private_rand = np.zeros((total_T, num_agents))                 # ici on ne gardera en mémoire que les dernières valeurs\n",
    "costs_train_agents_private_rand = np.zeros((total_T, num_agents))\n",
    "\n",
    "costs_test_private_rand = np.zeros(total_T)\n",
    "costs_train_private_rand = np.zeros(total_T)\n",
    "\n",
    "\n",
    "print(\"Iter: Agents_Mean       | Total \")\n",
    "for i in range (total_T) :\n",
    "    j = rd.randint(0, num_agents-1)\n",
    "    tracking[j] += 1\n",
    "\n",
    "    thetas_agents_private_rand = ml.stepForwardPrivate_2(thetas_agents_private_rand, X_agent_augmented, Y_agent, j, num_agents, mu, c, G, D, L_0, epsilon) \n",
    "\n",
    "    costs_train_agents_private_rand[i, j] = lr.cost(thetas_agents_private_rand[j], X_agent_augmented[j], Y_agent[j])\n",
    "    costs_test_agents_private_rand[i, j] = lr.cost(thetas_agents_private_rand[j], X_test_augmented, Y_test)\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        costs_train_private_rand[int(i/10)] = lr.costDecentralized(thetas_agents_private_rand, X_agent_augmented, Y_agent, num_agents, G, D, c, mu)\n",
    "        costs_test_private_rand[int(i/10)] = lr.costDecentralized(thetas_agents_private_rand, X_test_augmented, Y_test, num_agents, G, D, c, mu)\n",
    "        \n",
    "    if i % ((T/10)*num_agents) == 0 :\n",
    "        print(f'{int(i/num_agents):3} : ({np.mean(costs_train_agents_private_rand[i]):.4f} , {np.mean(costs_test_agents_private_rand[i]):.4f}) | ({costs_train_private_rand[int(i/10)]:.4f} , {costs_test_private_rand[int(i/10)]:.4f})')\n",
    "\n",
    "costs_train_agents_private_rand = util.reduce_cost_matrix(costs_train_agents_private_rand)\n",
    "costs_test_agents_private_rand = util.reduce_cost_matrix(costs_test_agents_private_rand)\n",
    "costs_train_private_rand = costs_train_private_rand[:T]\n",
    "costs_test_private_rand = costs_test_private_rand[:T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(costs_train_private_rand, label=\"Train\")\n",
    "plt.plot(costs_test_private_rand, label=\"Test\")\n",
    "plt.title(\"Private Model\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted drawing with constant epsilons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# DEFINING EPSILON_BAR\n",
    "epsilon_barre = 500\n",
    "L_0 = 0.25\n",
    "\n",
    "np.random.seed(seed)\n",
    "tracking  = np.zeros(num_agents)\n",
    "total_T = T*num_agents\n",
    "\n",
    "thetas_agents_private_weigh = [np.random.rand(X_agent_augmented[i].shape[1]) for i in range(num_agents)]\n",
    "costs_test_agents_private_weigh = np.zeros((total_T, num_agents))                 # ici on ne gardera en mémoire que les dernières valeurs\n",
    "costs_train_agents_private_weigh = np.zeros((total_T, num_agents))\n",
    "\n",
    "costs_test_private_weigh = np.zeros(total_T)\n",
    "costs_train_private_weigh = np.zeros(total_T)\n",
    "\n",
    "\n",
    "# on obtient les probabilités qu'on veut pour chaque modèle à chaque tirage\n",
    "coeffs_pond = np.zeros(num_agents)\n",
    "c_tot = 0\n",
    "for i in range (len(c)) :\n",
    "    c_tot += c[i]    \n",
    "for i in range (len(c)) :\n",
    "    coeffs_pond[i] = c[i]/c_tot\n",
    "    \n",
    "# des probabilités, on déduit l'espérance du nombre d'itérations pour chaque agent\n",
    "nb_iterations = np.zeros(num_agents)\n",
    "for i in range (num_agents):\n",
    "    nb_iterations = coeffs_pond * total_T\n",
    "\n",
    "\n",
    "# puis les epsilon correspondants pour chaque agent\n",
    "epsilon = np.zeros(num_agents)\n",
    "for i in range(num_agents): \n",
    "    epsilon[i] = epsilon_barre / nb_iterations[i]\n",
    "\"\"\"\n",
    "print(\"Agent : Iterations  | epsilon | epsilon_barre\")\n",
    "for i in range(num_agents):\n",
    "    print(f'{int(i):3} : ({nb_iterations[i]:.4f}) | ({epsilon[i]:.4f}) | ({epsilon[i]*nb_iterations[i]})')\n",
    "\"\"\"\n",
    "print()\n",
    "\n",
    "print(\"Iter: Agents_Mean       | Total \")\n",
    "\n",
    "for i in range(total_T) :\n",
    "    j = np.random.choice(10, 1, p=coeffs_pond)[0]\n",
    "    tracking[j] += 1\n",
    "\n",
    "    thetas_agents_private_weigh = ml.stepForwardPrivate_2(thetas_agents_private_weigh, X_agent_augmented, Y_agent, j, num_agents, mu, c, G, D, L_0, epsilon[j])\n",
    "\n",
    "    costs_train_agents_private_weigh[i, j] = (lr.cost(thetas_agents_private_weigh[j], X_agent_augmented[j], Y_agent[j]))\n",
    "    costs_test_agents_private_weigh[i, j] = (lr.cost(thetas_agents_private_weigh[j], X_test_augmented, Y_test))\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        costs_train_private_weigh[int(i/10)] = lr.costDecentralized(thetas_agents_private_weigh, X_agent_augmented, Y_agent, num_agents, G, D, c, mu)\n",
    "        costs_test_private_weigh[int(i/10)] = lr.costDecentralized(thetas_agents_private_weigh, X_test_augmented, Y_test, num_agents, G, D, c, mu)\n",
    "        \n",
    "        \n",
    "    if i % ((T/10)*num_agents) == 0 :\n",
    "        print(f'{int(i/num_agents):3} : ({np.mean(costs_train_agents_private_weigh[i]):.4f} , {np.mean(costs_test_agents_private_weigh[i]):.4f}) | ({costs_train_private_weigh[int(i/10)]:.4f} , {costs_test_private_weigh[int(i/10)]:.4f})')\n",
    "\n",
    "# costs_train_agents_weigh = util.reduce_cost_matrix(costs_train_agents_weigh)\n",
    "# costs_test_agents_weigh = util.reduce_cost_matrix(costs_test_agents_weigh)\n",
    "\n",
    "costs_train_agents_private_weigh_shifted = util.shift_non_zero_costs_to_front(costs_train_agents_private_weigh)\n",
    "costs_test_agents_private_weigh_shifted = util.shift_non_zero_costs_to_front(costs_test_agents_private_weigh)\n",
    "\n",
    "non_zero_counts = np.count_nonzero(costs_train_agents_private_weigh_shifted, axis=0)    \n",
    "max_non_zero = np.max(non_zero_counts)\n",
    "costs_train_private_weigh = costs_train_private_weigh[:T]\n",
    "costs_test_private_weigh = costs_test_private_weigh[:T]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Iter: Total_Mean_rand   | Total_Mean_weigh\")\n",
    "for i in range (total_T):\n",
    "    if i % ((T/10)*num_agents) == 0 :\n",
    "        print(f'{int(i/num_agents):3} : ({costs_train_private_rand[int(i/10)]:.4f} , {costs_test_private_rand[int(i/10)]:.4f}) | (({costs_train_private_weigh[int(i/10)]:.4f} , {costs_test_private_weigh[int(i/10)]:.4f})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(costs_train_private, label=\"Train normal\")\n",
    "plt.plot(costs_test_private, label=\"Test normal\")\n",
    "plt.plot(costs_train_private_weigh, label=\"Train weigh\")\n",
    "plt.plot(costs_test_private_weigh, label=\"Test weigh\")\n",
    "plt.title(\"Private Model\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.plot_curves_non_zero(num_agents, costs_train_agents_private_weigh_shifted, costs_test_agents_private_weigh_shifted, costs_train_private_weigh, costs_test_private_weigh, \"Multiple Agents - random weighted draw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted epsilons  implementing theorem 2 : optimal choice of epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(seed)\n",
    "tracking  = np.zeros(num_agents)\n",
    "total_T = T*num_agents\n",
    "\n",
    "thetas_agents_private_weigh_2 = [np.random.rand(X_agent_augmented[i].shape[1]) for i in range(num_agents)]\n",
    "costs_test_agents_private_weigh_2 = np.zeros((total_T, num_agents))                 # ici on ne gardera en mémoire que les dernières valeurs\n",
    "costs_train_agents_private_weigh_2 = np.zeros((total_T, num_agents))\n",
    "costs_test_private_weigh_2 = np.zeros(total_T)\n",
    "costs_train_private_weigh_2 = np.zeros(total_T)\n",
    "\n",
    "\n",
    "\n",
    "# on obtient les probabilités qu'on veut pour chaque modèle à chaque tirage\n",
    "coeffs_pond = np.zeros(num_agents)\n",
    "c_tot = 0\n",
    "for i in range (len(c)) :\n",
    "    c_tot += c[i]    \n",
    "for i in range (len(c)) :\n",
    "    coeffs_pond[i] = c[i]/c_tot\n",
    "    \n",
    "# on doit calculer grand C = 1 - sigma /(n*Lmax)\n",
    "# sigma - strongly convex  : correspond à Ql\n",
    "# Lmax : max Li, les Li sont les constantesblock lipschitz du gradient de Ql\n",
    "sigma = 0.05                                                                                       # randomly chosen at the moment\n",
    "Lmax = 20\n",
    "epsilon_bar = 500\n",
    "L_0 = 0.25\n",
    "\n",
    "big_c = 1 - sigma/(num_agents*Lmax)\n",
    "cube = big_c ** (1/3)\n",
    "print(cube)\n",
    "print()\n",
    "\n",
    "lambdas = np.zeros(num_agents)\n",
    "agent_choice = np.zeros(total_T)\n",
    "agent_pre = np.zeros(total_T)\n",
    "epsilons = np.zeros(total_T)\n",
    "\n",
    "# we have to know in advance at which iterations each machine wakes up, and we compute our lambdas\n",
    "\n",
    "\n",
    "for i in range(total_T) :\n",
    "    j = np.random.choice(10, 1, p=coeffs_pond)[0]\n",
    "    agent_choice[i] = j\n",
    "    res = (cube-1) / ((cube ** total_T)-1) * (cube ** (i+1))\n",
    "    agent_pre[i] = res\n",
    "    lambdas[j] += res\n",
    "    \n",
    "for i in range(total_T) :\n",
    "    epsilons[i] = agent_pre[i] * epsilon_bar / lambdas[int(agent_choice[i])]\n",
    "    \n",
    "\n",
    "count = 0\n",
    "sum = 0\n",
    "epsi_by_agent  = np.zeros(num_agents)\n",
    "count_by_agent = np.zeros(num_agents)\n",
    "first = np.zeros(num_agents)\n",
    "last = np.zeros(num_agents)\n",
    "\n",
    "for i in range(total_T):    \n",
    "    if epsi_by_agent[int(agent_choice[i])] == 0:\n",
    "        first[int(agent_choice[i])] = epsilons[i]\n",
    "    last[int(agent_choice[i])] = epsilons[i]\n",
    "    epsi_by_agent[int(agent_choice[i])] +=epsilons[i]\n",
    "    count_by_agent[int(agent_choice[i])] += 1\n",
    "    \n",
    "for i in range(num_agents):\n",
    "    epsi_by_agent[i] = epsi_by_agent[i] / count_by_agent[i]\n",
    "\n",
    "rate_epsi = first - last\n",
    "\n",
    "\n",
    "print(coeffs_pond)\n",
    "print(\"Iter: Agents_Mean       | Total \")\n",
    "\n",
    "for i in range(total_T) :\n",
    "    j = int(agent_choice[i])\n",
    "    epsi = epsilons[i]\n",
    "    thetas_agents_private_weigh_2 = ml.stepForwardPrivate_2(thetas_agents_private_weigh_2, X_agent_augmented, Y_agent, j, num_agents, mu, c, G, D, L_0, epsi)\n",
    "\n",
    "    costs_train_agents_private_weigh_2[i, j] = (lr.cost(thetas_agents_private_weigh_2[j], X_agent_augmented[j], Y_agent[j]))\n",
    "    costs_test_agents_private_weigh_2[i, j] = (lr.cost(thetas_agents_private_weigh_2[j], X_test_augmented, Y_test))\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        costs_train_private_weigh_2[int(i/10)] = lr.costDecentralized(thetas_agents_private_weigh_2, X_agent_augmented, Y_agent, num_agents, G, D, c, mu)\n",
    "        costs_test_private_weigh_2[int(i/10)] = lr.costDecentralized(thetas_agents_private_weigh_2, X_test_augmented, Y_test, num_agents, G, D, c, mu)\n",
    "        \n",
    "        \n",
    "    if i % ((T/10)*num_agents) == 0 :\n",
    "        print(f'{int(i/num_agents):3} : ({np.mean(costs_train_agents_private_weigh_2[i]):.4f} , {np.mean(costs_test_agents_private_weigh_2[i]):.4f}) | ({costs_train_private_weigh_2[int(i/10)]:.4f} , {costs_test_private_weigh_2[int(i/10)]:.4f})')\n",
    "\n",
    "# costs_train_agents_weigh_2 = util.reduce_cost_matrix(costs_train_agents_weigh_2)\n",
    "# costs_test_agents_weigh_2 = util.reduce_cost_matrix(costs_test_agents_weigh_2)\n",
    "\n",
    "costs_train_agents_private_weigh_shifted_2 = util.shift_non_zero_costs_to_front(costs_train_agents_private_weigh_2)\n",
    "costs_test_agents_private_weigh_shifted_2 = util.shift_non_zero_costs_to_front(costs_test_agents_private_weigh_2)\n",
    "\n",
    "non_zero_counts = np.count_nonzero(costs_train_agents_private_weigh_shifted_2, axis=0)    \n",
    "max_non_zero = np.max(non_zero_counts)\n",
    "costs_train_private_weigh_2 = costs_train_private_weigh_2[:T]\n",
    "costs_test_private_weigh_2 = costs_test_private_weigh_2[:T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Iter: Total_Mean_rand   | Total_Mean_weigh\")\n",
    "for i in range (total_T):\n",
    "    if i % ((T/10)*num_agents) == 0 :\n",
    "        print(f'{int(i/num_agents):3} : ({costs_train_private_weigh[int(i/10)]:.4f} , {costs_test_private_weigh[int(i/10)]:.4f}) | (({costs_train_private_weigh_2[int(i/10)]:.4f} , {costs_test_private_weigh_2[int(i/10)]:.4f})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"Agent : Iterations  | epsilon | epsilon_barre\")\n",
    "for i in range(num_agents):\n",
    "    print(f'{int(i):3} : ({nb_iterations[i]:.4f}) | ({epsilon[i]:.4f}) | ({epsilon[i]*nb_iterations[i]})')\n",
    "\n",
    "print()\n",
    "print(\"Agent : Iterations  | epsilon | epsilon_barre | delta_epsilon \")\n",
    "for i in range(num_agents):\n",
    "    print(f'{int(i):3} : ({count_by_agent[i]:.4f}) | ({epsi_by_agent[i]:.4f}) | ({epsi_by_agent[i]*count_by_agent[i]}) | ({rate_epsi[i]:.4f}))')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(costs_train_private, label=\"Train normal\")\n",
    "#plt.plot(costs_test_private, label=\"Test normal\")\n",
    "plt.plot(costs_train_private_weigh, label=\"Train weigh\")\n",
    "plt.plot(costs_test_private_weigh, label=\"Test weigh\")\n",
    "plt.plot(costs_train_private_weigh_2, label=\"Train weigh 2\")\n",
    "plt.plot(costs_test_private_weigh_2, label=\"Test weigh 2\")\n",
    "plt.title(\"Private Model\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs_train_private_weigh = costs_train_private_weigh[100:]\n",
    "costs_test_private_weigh = costs_test_private_weigh[100:]\n",
    "costs_train_private_weigh_2 = costs_train_private_weigh_2[100:]\n",
    "costs_test_private_weigh_2 = costs_test_private_weigh_2[100:]\n",
    "\n",
    "plt.plot(costs_train_private_weigh, label=\"Train weigh\")\n",
    "plt.plot(costs_test_private_weigh, label=\"Test weigh\")\n",
    "plt.plot(costs_train_private_weigh_2, label=\"Train weigh 2\")\n",
    "plt.plot(costs_test_private_weigh_2, label=\"Test weigh 2\")\n",
    "plt.title(\"Private Model\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.plot_curves_non_zero(num_agents, costs_train_agents_private_weigh_shifted_2, costs_test_agents_private_weigh_shifted_2, costs_train_private_weigh_2, costs_test_private_weigh_2, \"Multiple Agents - random weighted draw\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "col_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
